{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fernsrea/reimagined-eureka/blob/main/CIFAR_10_CIFAR_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jRnYLF-sE8H",
        "outputId": "4054469e-c165-4112-ced4-5ce75ec9b9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'flow_matching' already exists and is not an empty directory.\n",
            "/content/flow_matching\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/flow_matching.git\n",
        "%cd flow_matching"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd examples/image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1R7FXmqsYCR",
        "outputId": "e7793e58-f416-434b-df5a-15a725429de7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flow_matching/examples/image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzyJxPEasbeA",
        "outputId": "9e608392-58a8-4d44-881a-4125ca62e635"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchmetrics[image] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (0.14.3)\n",
            "Requirement already satisfied: torch-fidelity<=0.4.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSbE2uw71gz3",
        "outputId": "a591aa93-91b8-43b3-b0f5-06ee9e899fc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flow_matching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4SivJfO2boL",
        "outputId": "9b7c4afe-1b51-47c5-cedd-b4160e311bf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flow_matching in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (from flow_matching) (0.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flow_matching) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq->flow_matching) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flow_matching) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --output_dir output_cifar10 --batch_size 64 --accum_iter=1 --eval_frequency=100 --epochs=3000 --class_drop_prob=1.0 --cfg_scale=0.0 --compute_fid --ode_method heun2 --ode_options '{\"nfe\": 50}' --use_ema --edm_schedule --skewed_timesteps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JvqNqDftWtS",
        "outputId": "02975d3f-6d60-49a2-80a4-5d3e43f7fe92"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not using distributed mode\n",
            "2025-04-17 08:53:07 INFO     job dir: /content/flow_matching/examples/image\n",
            "2025-04-17 08:53:07 INFO     Namespace(batch_size=64,\n",
            "epochs=3000,\n",
            "accum_iter=1,\n",
            "lr=0.0001,\n",
            "optimizer_betas=[0.9,\n",
            "0.95],\n",
            "decay_lr=False,\n",
            "class_drop_prob=1.0,\n",
            "skewed_timesteps=True,\n",
            "edm_schedule=True,\n",
            "use_ema=True,\n",
            "dataset='cifar10',\n",
            "data_path='./data/image_generation',\n",
            "output_dir='output_cifar10',\n",
            "ode_method='heun2',\n",
            "ode_options={'nfe': 50},\n",
            "sym=0.0,\n",
            "temp=1.0,\n",
            "sym_func=False,\n",
            "sampling_dtype='float32',\n",
            "cfg_scale=0.0,\n",
            "fid_samples=50000,\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='',\n",
            "start_epoch=0,\n",
            "eval_only=False,\n",
            "eval_frequency=100,\n",
            "compute_fid=True,\n",
            "save_fid_samples=False,\n",
            "num_workers=10,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "test_run=False,\n",
            "discrete_flow_matching=False,\n",
            "discrete_fm_steps=1024,\n",
            "distributed=False)\n",
            "2025-04-17 08:53:07 INFO     Saving args to output_cifar10/args.json\n",
            "2025-04-17 08:53:07 INFO     Initializing Dataset: cifar10\n",
            "100% 170M/170M [00:04<00:00, 41.0MB/s]\n",
            "2025-04-17 08:53:14 INFO     Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data/image_generation\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 RandomHorizontalFlip(p=0.5)\n",
            "                 ToDtype(scale=True)\n",
            "           )\n",
            "2025-04-17 08:53:14 INFO     Intializing DataLoader\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-04-17 08:53:14 INFO     <torch.utils.data.distributed.DistributedSampler object at 0x7bc46a52b410>\n",
            "2025-04-17 08:53:14 INFO     Initializing Model\n",
            "2025-04-17 08:53:15 INFO     EMA(\n",
            "  (model): UNetModel(in_channels=3, model_channels=128, out_channels=3, num_res_blocks=4, attention_resolutions=[2], dropout=0.3, channel_mult=[2, 2, 2], conv_resample=False, dims=2, num_classes=None, use_checkpoint=False, num_heads=1, num_head_channels=-1, num_heads_upsample=1, use_scale_shift_norm=True, resblock_updown=False, use_new_attention_order=True, with_fourier_features=False, ignore_time=False, input_projection=True, image_size=-1, _target_='lib.models.gd_unet.UNetModel')\n",
            "  (shadow_params): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512x128 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float32 of size 256x3x3x3 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (8): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (9): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (10): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (11): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (12): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (13): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (14): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (15): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (16): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (17): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (18): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (19): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (20): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (21): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (22): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (23): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (24): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (25): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (26): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (27): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (28): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (29): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (30): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (31): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (32): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (33): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (34): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (35): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (36): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (37): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (38): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (39): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (40): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (41): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (42): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (43): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (44): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (45): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (46): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (47): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (48): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (49): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (50): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (51): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (52): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (53): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (54): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (55): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (56): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (57): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (58): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (59): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (60): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (61): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (62): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (63): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (64): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (65): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (66): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (67): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (68): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (69): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (70): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (71): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (72): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (73): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (74): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (75): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (76): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (77): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (78): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (79): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (80): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (81): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (82): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (83): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (84): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (85): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (86): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (87): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (88): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (89): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (90): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (91): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (92): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (93): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (94): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (95): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (96): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (97): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (98): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (99): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (100): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (101): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (102): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (103): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (104): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (105): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (106): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (107): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (108): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (109): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (110): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (111): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (112): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (113): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (114): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (115): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (116): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (117): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (118): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (119): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (120): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (121): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (122): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (123): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (124): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (125): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (126): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (127): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (128): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (129): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (130): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (131): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (132): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (133): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (134): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (135): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (136): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (137): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (138): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (139): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (140): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (141): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (142): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (143): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (144): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (145): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (146): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (147): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (148): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (149): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (150): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (151): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (152): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (153): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (154): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (155): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (156): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (157): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (158): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (159): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (160): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (161): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (162): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (163): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (164): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (165): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (166): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (167): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (168): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (169): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (170): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (171): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (172): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (173): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (174): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (175): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (176): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (177): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (178): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (179): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (180): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (181): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (182): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (183): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (184): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (185): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (186): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (187): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (188): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (189): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (190): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (191): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (192): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (193): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (194): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (195): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (196): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (197): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (198): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (199): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (200): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (201): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (202): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (203): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (204): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (205): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (206): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (207): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (208): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (209): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (210): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (211): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (212): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (213): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (214): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (215): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (216): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (217): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (218): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (219): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (220): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (221): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (222): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (223): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (224): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (225): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (226): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (227): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (228): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (229): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (230): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (231): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (232): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (233): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (234): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (235): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (236): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (237): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (238): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (239): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (240): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (241): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (242): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (243): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (244): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (245): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (246): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (247): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (248): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (249): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (250): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (251): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (252): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (253): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (254): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (255): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (256): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (257): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (258): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (259): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (260): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (261): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (262): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (263): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (264): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (265): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (266): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (267): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (268): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (269): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (270): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (271): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (272): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (273): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (274): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (275): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (276): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (277): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (278): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (279): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (280): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (281): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (282): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (283): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (284): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (285): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (286): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (287): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (288): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (289): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (290): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (291): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (292): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (293): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (294): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (295): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (296): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (297): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (298): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (299): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (300): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (301): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (302): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (303): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (304): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (305): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (306): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (307): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (308): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (309): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (310): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (311): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (312): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (313): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (314): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (315): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (316): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (317): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (318): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (319): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (320): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (321): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (322): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (323): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (324): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (325): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (326): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (327): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (328): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (329): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (330): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (331): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (332): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (333): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (334): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (335): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (336): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (337): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (338): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (339): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (340): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (341): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (342): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (343): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (344): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (345): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (346): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (347): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (348): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (349): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (350): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (351): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (352): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (353): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (354): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (355): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (356): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (357): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (358): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (359): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (360): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (361): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (362): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (363): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (364): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (365): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (366): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (367): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (368): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (369): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (370): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (371): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (372): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (373): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (374): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (375): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (376): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (377): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (378): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (379): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (380): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (381): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (382): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (383): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (384): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (385): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (386): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (387): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (388): Parameter containing: [torch.float32 of size 3x256x3x3 (cuda:0)]\n",
            "      (389): Parameter containing: [torch.float32 of size 3 (cuda:0)]\n",
            "  )\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning rate: 1.00e-04\n",
            "2025-04-17 08:53:15 INFO     Accumulate grad iterations: 1\n",
            "2025-04-17 08:53:15 INFO     Effective batch size: 64\n",
            "2025-04-17 08:53:15 INFO     Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: [0.9, 0.95]\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning-Rate Schedule: <torch.optim.lr_scheduler.ConstantLR object at 0x7bc461a04190>\n",
            "/content/flow_matching/examples/image/training/grad_scaler.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "2025-04-17 08:53:15 INFO     Start from 0 to 3000 epochs\n",
            "/content/flow_matching/examples/image/training/train_loop.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "2025-04-17 08:53:20 INFO     Epoch 0 [0/781]: loss = 1.2690505981445312, lr = 0.0001\n",
            "2025-04-17 08:53:53 INFO     Epoch 0 [50/781]: loss = 0.39588260650634766, lr = 0.0001\n",
            "2025-04-17 08:54:26 INFO     Epoch 0 [100/781]: loss = 0.3167325258255005, lr = 0.0001\n",
            "2025-04-17 08:55:00 INFO     Epoch 0 [150/781]: loss = 0.2574637532234192, lr = 0.0001\n",
            "2025-04-17 08:55:34 INFO     Epoch 0 [200/781]: loss = 0.21366429328918457, lr = 0.0001\n",
            "2025-04-17 08:56:08 INFO     Epoch 0 [250/781]: loss = 0.2729591727256775, lr = 0.0001\n",
            "2025-04-17 08:56:42 INFO     Epoch 0 [300/781]: loss = 0.2141873836517334, lr = 0.0001\n",
            "2025-04-17 08:57:17 INFO     Epoch 0 [350/781]: loss = 0.22606389224529266, lr = 0.0001\n",
            "2025-04-17 08:57:51 INFO     Epoch 0 [400/781]: loss = 0.2152235209941864, lr = 0.0001\n",
            "2025-04-17 08:58:25 INFO     Epoch 0 [450/781]: loss = 0.22886864840984344, lr = 0.0001\n",
            "2025-04-17 08:58:59 INFO     Epoch 0 [500/781]: loss = 0.23081204295158386, lr = 0.0001\n",
            "2025-04-17 08:59:33 INFO     Epoch 0 [550/781]: loss = 0.2134130895137787, lr = 0.0001\n",
            "2025-04-17 09:00:07 INFO     Epoch 0 [600/781]: loss = 0.20946133136749268, lr = 0.0001\n",
            "2025-04-17 09:00:42 INFO     Epoch 0 [650/781]: loss = 0.2337268441915512, lr = 0.0001\n",
            "2025-04-17 09:01:16 INFO     Epoch 0 [700/781]: loss = 0.22273653745651245, lr = 0.0001\n",
            "2025-04-17 09:01:50 INFO     Epoch 0 [750/781]: loss = 0.2008974850177765, lr = 0.0001\n",
            "2025-04-17 09:02:12 INFO     Epoch 1 [0/781]: loss = 0.19051897525787354, lr = 0.0001\n",
            "2025-04-17 09:02:46 INFO     Epoch 1 [50/781]: loss = 0.21678398549556732, lr = 0.0001\n",
            "2025-04-17 09:03:20 INFO     Epoch 1 [100/781]: loss = 0.20141810178756714, lr = 0.0001\n",
            "2025-04-17 09:03:55 INFO     Epoch 1 [150/781]: loss = 0.20764145255088806, lr = 0.0001\n",
            "2025-04-17 09:04:29 INFO     Epoch 1 [200/781]: loss = 0.18706795573234558, lr = 0.0001\n",
            "2025-04-17 09:05:03 INFO     Epoch 1 [250/781]: loss = 0.23258349299430847, lr = 0.0001\n",
            "2025-04-17 09:05:37 INFO     Epoch 1 [300/781]: loss = 0.22095182538032532, lr = 0.0001\n",
            "2025-04-17 09:06:11 INFO     Epoch 1 [350/781]: loss = 0.20588165521621704, lr = 0.0001\n",
            "2025-04-17 09:06:45 INFO     Epoch 1 [400/781]: loss = 0.18197381496429443, lr = 0.0001\n",
            "2025-04-17 09:07:19 INFO     Epoch 1 [450/781]: loss = 0.19729745388031006, lr = 0.0001\n",
            "2025-04-17 09:07:53 INFO     Epoch 1 [500/781]: loss = 0.18707603216171265, lr = 0.0001\n",
            "2025-04-17 09:08:28 INFO     Epoch 1 [550/781]: loss = 0.2105555534362793, lr = 0.0001\n",
            "2025-04-17 09:09:02 INFO     Epoch 1 [600/781]: loss = 0.1953573077917099, lr = 0.0001\n",
            "2025-04-17 09:09:36 INFO     Epoch 1 [650/781]: loss = 0.18791460990905762, lr = 0.0001\n",
            "2025-04-17 09:10:10 INFO     Epoch 1 [700/781]: loss = 0.20253634452819824, lr = 0.0001\n",
            "2025-04-17 09:10:44 INFO     Epoch 1 [750/781]: loss = 0.23993274569511414, lr = 0.0001\n",
            "2025-04-17 09:11:07 INFO     Epoch 2 [0/781]: loss = 0.1836549937725067, lr = 0.0001\n",
            "2025-04-17 09:11:41 INFO     Epoch 2 [50/781]: loss = 0.19532375037670135, lr = 0.0001\n",
            "2025-04-17 09:12:15 INFO     Epoch 2 [100/781]: loss = 0.18377122282981873, lr = 0.0001\n",
            "2025-04-17 09:12:50 INFO     Epoch 2 [150/781]: loss = 0.16717159748077393, lr = 0.0001\n",
            "2025-04-17 09:13:24 INFO     Epoch 2 [200/781]: loss = 0.20628076791763306, lr = 0.0001\n",
            "2025-04-17 09:13:58 INFO     Epoch 2 [250/781]: loss = 0.19085656106472015, lr = 0.0001\n",
            "2025-04-17 09:14:32 INFO     Epoch 2 [300/781]: loss = 0.17578762769699097, lr = 0.0001\n",
            "2025-04-17 09:15:06 INFO     Epoch 2 [350/781]: loss = 0.2072685956954956, lr = 0.0001\n",
            "2025-04-17 09:15:40 INFO     Epoch 2 [400/781]: loss = 0.19337467849254608, lr = 0.0001\n",
            "2025-04-17 09:16:14 INFO     Epoch 2 [450/781]: loss = 0.21467474102973938, lr = 0.0001\n",
            "2025-04-17 09:16:48 INFO     Epoch 2 [500/781]: loss = 0.20417504012584686, lr = 0.0001\n",
            "2025-04-17 09:17:22 INFO     Epoch 2 [550/781]: loss = 0.20916643738746643, lr = 0.0001\n",
            "2025-04-17 09:17:57 INFO     Epoch 2 [600/781]: loss = 0.19796261191368103, lr = 0.0001\n",
            "2025-04-17 09:18:31 INFO     Epoch 2 [650/781]: loss = 0.22070658206939697, lr = 0.0001\n",
            "2025-04-17 09:19:05 INFO     Epoch 2 [700/781]: loss = 0.194630965590477, lr = 0.0001\n",
            "2025-04-17 09:19:39 INFO     Epoch 2 [750/781]: loss = 0.2237108200788498, lr = 0.0001\n",
            "2025-04-17 09:20:01 INFO     Epoch 3 [0/781]: loss = 0.21703355014324188, lr = 0.0001\n",
            "2025-04-17 09:20:35 INFO     Epoch 3 [50/781]: loss = 0.20931218564510345, lr = 0.0001\n",
            "2025-04-17 09:21:09 INFO     Epoch 3 [100/781]: loss = 0.1962609738111496, lr = 0.0001\n",
            "2025-04-17 09:21:43 INFO     Epoch 3 [150/781]: loss = 0.18569374084472656, lr = 0.0001\n",
            "2025-04-17 09:22:17 INFO     Epoch 3 [200/781]: loss = 0.19049876928329468, lr = 0.0001\n",
            "2025-04-17 09:22:51 INFO     Epoch 3 [250/781]: loss = 0.18748316168785095, lr = 0.0001\n",
            "2025-04-17 09:23:25 INFO     Epoch 3 [300/781]: loss = 0.19134342670440674, lr = 0.0001\n",
            "2025-04-17 09:23:59 INFO     Epoch 3 [350/781]: loss = 0.18596872687339783, lr = 0.0001\n",
            "2025-04-17 09:24:34 INFO     Epoch 3 [400/781]: loss = 0.18249867856502533, lr = 0.0001\n",
            "2025-04-17 09:25:08 INFO     Epoch 3 [450/781]: loss = 0.20058941841125488, lr = 0.0001\n",
            "2025-04-17 09:25:42 INFO     Epoch 3 [500/781]: loss = 0.2027120292186737, lr = 0.0001\n",
            "2025-04-17 09:26:16 INFO     Epoch 3 [550/781]: loss = 0.20231735706329346, lr = 0.0001\n",
            "2025-04-17 09:26:50 INFO     Epoch 3 [600/781]: loss = 0.20439958572387695, lr = 0.0001\n",
            "2025-04-17 09:27:24 INFO     Epoch 3 [650/781]: loss = 0.18566159904003143, lr = 0.0001\n",
            "2025-04-17 09:27:58 INFO     Epoch 3 [700/781]: loss = 0.2061748504638672, lr = 0.0001\n",
            "2025-04-17 09:28:32 INFO     Epoch 3 [750/781]: loss = 0.20343220233917236, lr = 0.0001\n",
            "2025-04-17 09:28:55 INFO     Epoch 4 [0/781]: loss = 0.19190876185894012, lr = 0.0001\n",
            "2025-04-17 09:29:29 INFO     Epoch 4 [50/781]: loss = 0.1891046166419983, lr = 0.0001\n",
            "2025-04-17 09:30:03 INFO     Epoch 4 [100/781]: loss = 0.1839616298675537, lr = 0.0001\n",
            "2025-04-17 09:30:37 INFO     Epoch 4 [150/781]: loss = 0.18303261697292328, lr = 0.0001\n",
            "2025-04-17 09:31:11 INFO     Epoch 4 [200/781]: loss = 0.18782281875610352, lr = 0.0001\n",
            "2025-04-17 09:31:45 INFO     Epoch 4 [250/781]: loss = 0.20793776214122772, lr = 0.0001\n",
            "2025-04-17 09:32:19 INFO     Epoch 4 [300/781]: loss = 0.175978422164917, lr = 0.0001\n",
            "2025-04-17 09:32:54 INFO     Epoch 4 [350/781]: loss = 0.1807139366865158, lr = 0.0001\n",
            "2025-04-17 09:33:28 INFO     Epoch 4 [400/781]: loss = 0.19041812419891357, lr = 0.0001\n",
            "2025-04-17 09:34:02 INFO     Epoch 4 [450/781]: loss = 0.16084079444408417, lr = 0.0001\n",
            "2025-04-17 09:34:36 INFO     Epoch 4 [500/781]: loss = 0.20923976600170135, lr = 0.0001\n",
            "2025-04-17 09:35:10 INFO     Epoch 4 [550/781]: loss = 0.19188305735588074, lr = 0.0001\n",
            "2025-04-17 09:35:44 INFO     Epoch 4 [600/781]: loss = 0.18772852420806885, lr = 0.0001\n",
            "2025-04-17 09:36:18 INFO     Epoch 4 [650/781]: loss = 0.19194619357585907, lr = 0.0001\n",
            "2025-04-17 09:36:52 INFO     Epoch 4 [700/781]: loss = 0.18795692920684814, lr = 0.0001\n",
            "2025-04-17 09:37:27 INFO     Epoch 4 [750/781]: loss = 0.191559836268425, lr = 0.0001\n",
            "2025-04-17 09:37:49 INFO     Epoch 5 [0/781]: loss = 0.19172146916389465, lr = 0.0001\n",
            "2025-04-17 09:38:23 INFO     Epoch 5 [50/781]: loss = 0.1819886416196823, lr = 0.0001\n",
            "2025-04-17 09:38:57 INFO     Epoch 5 [100/781]: loss = 0.18365070223808289, lr = 0.0001\n",
            "2025-04-17 09:39:31 INFO     Epoch 5 [150/781]: loss = 0.18155574798583984, lr = 0.0001\n",
            "2025-04-17 09:40:05 INFO     Epoch 5 [200/781]: loss = 0.20613281428813934, lr = 0.0001\n",
            "2025-04-17 09:40:40 INFO     Epoch 5 [250/781]: loss = 0.19818627834320068, lr = 0.0001\n",
            "2025-04-17 09:41:14 INFO     Epoch 5 [300/781]: loss = 0.1705714762210846, lr = 0.0001\n",
            "2025-04-17 09:41:48 INFO     Epoch 5 [350/781]: loss = 0.1712859869003296, lr = 0.0001\n",
            "2025-04-17 09:42:22 INFO     Epoch 5 [400/781]: loss = 0.18512040376663208, lr = 0.0001\n",
            "2025-04-17 09:42:56 INFO     Epoch 5 [450/781]: loss = 0.17423617839813232, lr = 0.0001\n",
            "2025-04-17 09:43:30 INFO     Epoch 5 [500/781]: loss = 0.20096322894096375, lr = 0.0001\n",
            "2025-04-17 09:44:05 INFO     Epoch 5 [550/781]: loss = 0.2231142818927765, lr = 0.0001\n",
            "2025-04-17 09:44:39 INFO     Epoch 5 [600/781]: loss = 0.18500111997127533, lr = 0.0001\n",
            "2025-04-17 09:45:13 INFO     Epoch 5 [650/781]: loss = 0.19109341502189636, lr = 0.0001\n",
            "2025-04-17 09:45:47 INFO     Epoch 5 [700/781]: loss = 0.206669420003891, lr = 0.0001\n",
            "2025-04-17 09:46:21 INFO     Epoch 5 [750/781]: loss = 0.17921707034111023, lr = 0.0001\n",
            "2025-04-17 09:46:43 INFO     Epoch 6 [0/781]: loss = 0.19302301108837128, lr = 0.0001\n",
            "2025-04-17 09:47:18 INFO     Epoch 6 [50/781]: loss = 0.18664507567882538, lr = 0.0001\n",
            "2025-04-17 09:47:52 INFO     Epoch 6 [100/781]: loss = 0.19506633281707764, lr = 0.0001\n",
            "2025-04-17 09:48:26 INFO     Epoch 6 [150/781]: loss = 0.18421494960784912, lr = 0.0001\n",
            "2025-04-17 09:49:00 INFO     Epoch 6 [200/781]: loss = 0.18035152554512024, lr = 0.0001\n",
            "2025-04-17 09:49:34 INFO     Epoch 6 [250/781]: loss = 0.19770073890686035, lr = 0.0001\n",
            "2025-04-17 09:50:08 INFO     Epoch 6 [300/781]: loss = 0.1943836808204651, lr = 0.0001\n",
            "2025-04-17 09:50:42 INFO     Epoch 6 [350/781]: loss = 0.1712065190076828, lr = 0.0001\n",
            "2025-04-17 09:51:16 INFO     Epoch 6 [400/781]: loss = 0.1639152467250824, lr = 0.0001\n",
            "2025-04-17 09:51:50 INFO     Epoch 6 [450/781]: loss = 0.17477063834667206, lr = 0.0001\n",
            "2025-04-17 09:52:24 INFO     Epoch 6 [500/781]: loss = 0.19122302532196045, lr = 0.0001\n",
            "2025-04-17 09:52:58 INFO     Epoch 6 [550/781]: loss = 0.1961708664894104, lr = 0.0001\n",
            "2025-04-17 09:53:32 INFO     Epoch 6 [600/781]: loss = 0.1814488172531128, lr = 0.0001\n",
            "2025-04-17 09:54:06 INFO     Epoch 6 [650/781]: loss = 0.18622741103172302, lr = 0.0001\n",
            "2025-04-17 09:54:40 INFO     Epoch 6 [700/781]: loss = 0.19513118267059326, lr = 0.0001\n",
            "2025-04-17 09:55:14 INFO     Epoch 6 [750/781]: loss = 0.19307929277420044, lr = 0.0001\n",
            "2025-04-17 09:55:36 INFO     Epoch 7 [0/781]: loss = 0.17231541872024536, lr = 0.0001\n",
            "2025-04-17 09:56:10 INFO     Epoch 7 [50/781]: loss = 0.18340007960796356, lr = 0.0001\n",
            "2025-04-17 09:56:44 INFO     Epoch 7 [100/781]: loss = 0.20542728900909424, lr = 0.0001\n",
            "2025-04-17 09:57:18 INFO     Epoch 7 [150/781]: loss = 0.17269472777843475, lr = 0.0001\n",
            "2025-04-17 09:57:52 INFO     Epoch 7 [200/781]: loss = 0.21998058259487152, lr = 0.0001\n",
            "2025-04-17 09:58:26 INFO     Epoch 7 [250/781]: loss = 0.19040118157863617, lr = 0.0001\n",
            "2025-04-17 09:59:00 INFO     Epoch 7 [300/781]: loss = 0.1739916056394577, lr = 0.0001\n",
            "2025-04-17 09:59:34 INFO     Epoch 7 [350/781]: loss = 0.19322258234024048, lr = 0.0001\n",
            "2025-04-17 10:00:09 INFO     Epoch 7 [400/781]: loss = 0.18947991728782654, lr = 0.0001\n",
            "2025-04-17 10:00:43 INFO     Epoch 7 [450/781]: loss = 0.16746798157691956, lr = 0.0001\n",
            "2025-04-17 10:01:17 INFO     Epoch 7 [500/781]: loss = 0.17832587659358978, lr = 0.0001\n",
            "2025-04-17 10:01:51 INFO     Epoch 7 [550/781]: loss = 0.18300525844097137, lr = 0.0001\n",
            "2025-04-17 10:02:25 INFO     Epoch 7 [600/781]: loss = 0.18154005706310272, lr = 0.0001\n",
            "2025-04-17 10:02:59 INFO     Epoch 7 [650/781]: loss = 0.20559941232204437, lr = 0.0001\n",
            "2025-04-17 10:03:33 INFO     Epoch 7 [700/781]: loss = 0.1907215118408203, lr = 0.0001\n",
            "2025-04-17 10:04:07 INFO     Epoch 7 [750/781]: loss = 0.1854335069656372, lr = 0.0001\n",
            "2025-04-17 10:04:29 INFO     Epoch 8 [0/781]: loss = 0.20283488929271698, lr = 0.0001\n",
            "2025-04-17 10:05:03 INFO     Epoch 8 [50/781]: loss = 0.18546846508979797, lr = 0.0001\n",
            "2025-04-17 10:05:37 INFO     Epoch 8 [100/781]: loss = 0.1961940973997116, lr = 0.0001\n",
            "2025-04-17 10:06:11 INFO     Epoch 8 [150/781]: loss = 0.18177299201488495, lr = 0.0001\n",
            "2025-04-17 10:06:44 INFO     Epoch 8 [200/781]: loss = 0.17395305633544922, lr = 0.0001\n",
            "2025-04-17 10:07:18 INFO     Epoch 8 [250/781]: loss = 0.19678586721420288, lr = 0.0001\n",
            "2025-04-17 10:07:52 INFO     Epoch 8 [300/781]: loss = 0.2043527066707611, lr = 0.0001\n",
            "2025-04-17 10:08:26 INFO     Epoch 8 [350/781]: loss = 0.17867235839366913, lr = 0.0001\n",
            "2025-04-17 10:09:00 INFO     Epoch 8 [400/781]: loss = 0.18099266290664673, lr = 0.0001\n",
            "2025-04-17 10:09:34 INFO     Epoch 8 [450/781]: loss = 0.15543508529663086, lr = 0.0001\n",
            "2025-04-17 10:10:08 INFO     Epoch 8 [500/781]: loss = 0.19663546979427338, lr = 0.0001\n",
            "2025-04-17 10:10:42 INFO     Epoch 8 [550/781]: loss = 0.1810828149318695, lr = 0.0001\n",
            "2025-04-17 10:11:15 INFO     Epoch 8 [600/781]: loss = 0.16483554244041443, lr = 0.0001\n",
            "2025-04-17 10:11:49 INFO     Epoch 8 [650/781]: loss = 0.20616072416305542, lr = 0.0001\n",
            "2025-04-17 10:12:23 INFO     Epoch 8 [700/781]: loss = 0.18997815251350403, lr = 0.0001\n",
            "2025-04-17 10:12:57 INFO     Epoch 8 [750/781]: loss = 0.1936555802822113, lr = 0.0001\n",
            "2025-04-17 10:13:19 INFO     Epoch 9 [0/781]: loss = 0.1767980307340622, lr = 0.0001\n",
            "2025-04-17 10:13:53 INFO     Epoch 9 [50/781]: loss = 0.1783907264471054, lr = 0.0001\n",
            "2025-04-17 10:14:27 INFO     Epoch 9 [100/781]: loss = 0.20202267169952393, lr = 0.0001\n",
            "2025-04-17 10:15:01 INFO     Epoch 9 [150/781]: loss = 0.18218904733657837, lr = 0.0001\n",
            "2025-04-17 10:15:35 INFO     Epoch 9 [200/781]: loss = 0.16778044402599335, lr = 0.0001\n",
            "2025-04-17 10:16:09 INFO     Epoch 9 [250/781]: loss = 0.19565360248088837, lr = 0.0001\n",
            "2025-04-17 10:16:43 INFO     Epoch 9 [300/781]: loss = 0.1887447088956833, lr = 0.0001\n",
            "2025-04-17 10:17:16 INFO     Epoch 9 [350/781]: loss = 0.1834096908569336, lr = 0.0001\n",
            "2025-04-17 10:17:50 INFO     Epoch 9 [400/781]: loss = 0.19651281833648682, lr = 0.0001\n",
            "2025-04-17 10:18:24 INFO     Epoch 9 [450/781]: loss = 0.16701172292232513, lr = 0.0001\n",
            "2025-04-17 10:18:58 INFO     Epoch 9 [500/781]: loss = 0.1977374255657196, lr = 0.0001\n",
            "2025-04-17 10:19:32 INFO     Epoch 9 [550/781]: loss = 0.17805258929729462, lr = 0.0001\n",
            "2025-04-17 10:20:06 INFO     Epoch 9 [600/781]: loss = 0.17720097303390503, lr = 0.0001\n",
            "2025-04-17 10:20:40 INFO     Epoch 9 [650/781]: loss = 0.19044332206249237, lr = 0.0001\n",
            "2025-04-17 10:21:14 INFO     Epoch 9 [700/781]: loss = 0.19674187898635864, lr = 0.0001\n",
            "2025-04-17 10:21:48 INFO     Epoch 9 [750/781]: loss = 0.19547538459300995, lr = 0.0001\n",
            "2025-04-17 10:22:10 INFO     Epoch 10 [0/781]: loss = 0.17076699435710907, lr = 0.0001\n",
            "2025-04-17 10:22:44 INFO     Epoch 10 [50/781]: loss = 0.1862916201353073, lr = 0.0001\n",
            "2025-04-17 10:23:18 INFO     Epoch 10 [100/781]: loss = 0.18606525659561157, lr = 0.0001\n",
            "2025-04-17 10:23:52 INFO     Epoch 10 [150/781]: loss = 0.18241676688194275, lr = 0.0001\n",
            "2025-04-17 10:24:26 INFO     Epoch 10 [200/781]: loss = 0.20786850154399872, lr = 0.0001\n",
            "2025-04-17 10:25:01 INFO     Epoch 10 [250/781]: loss = 0.19596070051193237, lr = 0.0001\n",
            "2025-04-17 10:25:35 INFO     Epoch 10 [300/781]: loss = 0.17397837340831757, lr = 0.0001\n",
            "2025-04-17 10:26:09 INFO     Epoch 10 [350/781]: loss = 0.18165133893489838, lr = 0.0001\n",
            "2025-04-17 10:26:43 INFO     Epoch 10 [400/781]: loss = 0.20199429988861084, lr = 0.0001\n",
            "2025-04-17 10:27:17 INFO     Epoch 10 [450/781]: loss = 0.18205194175243378, lr = 0.0001\n",
            "2025-04-17 10:27:51 INFO     Epoch 10 [500/781]: loss = 0.20143213868141174, lr = 0.0001\n",
            "2025-04-17 10:28:26 INFO     Epoch 10 [550/781]: loss = 0.21959921717643738, lr = 0.0001\n",
            "2025-04-17 10:29:00 INFO     Epoch 10 [600/781]: loss = 0.189347505569458, lr = 0.0001\n",
            "2025-04-17 10:29:34 INFO     Epoch 10 [650/781]: loss = 0.19349059462547302, lr = 0.0001\n",
            "2025-04-17 10:30:08 INFO     Epoch 10 [700/781]: loss = 0.1924455612897873, lr = 0.0001\n",
            "2025-04-17 10:30:42 INFO     Epoch 10 [750/781]: loss = 0.18420687317848206, lr = 0.0001\n",
            "2025-04-17 10:31:04 INFO     Epoch 11 [0/781]: loss = 0.1970309466123581, lr = 0.0001\n",
            "2025-04-17 10:31:39 INFO     Epoch 11 [50/781]: loss = 0.19105744361877441, lr = 0.0001\n",
            "2025-04-17 10:32:13 INFO     Epoch 11 [100/781]: loss = 0.1946110725402832, lr = 0.0001\n",
            "2025-04-17 10:32:47 INFO     Epoch 11 [150/781]: loss = 0.20001018047332764, lr = 0.0001\n",
            "2025-04-17 10:33:21 INFO     Epoch 11 [200/781]: loss = 0.18796232342720032, lr = 0.0001\n",
            "2025-04-17 10:33:55 INFO     Epoch 11 [250/781]: loss = 0.20737320184707642, lr = 0.0001\n",
            "2025-04-17 10:34:29 INFO     Epoch 11 [300/781]: loss = 0.17302647233009338, lr = 0.0001\n",
            "2025-04-17 10:35:04 INFO     Epoch 11 [350/781]: loss = 0.20097756385803223, lr = 0.0001\n",
            "2025-04-17 10:35:38 INFO     Epoch 11 [400/781]: loss = 0.18393635749816895, lr = 0.0001\n",
            "2025-04-17 10:36:12 INFO     Epoch 11 [450/781]: loss = 0.1680130958557129, lr = 0.0001\n",
            "2025-04-17 10:36:46 INFO     Epoch 11 [500/781]: loss = 0.1749754548072815, lr = 0.0001\n",
            "2025-04-17 10:37:21 INFO     Epoch 11 [550/781]: loss = 0.2028127759695053, lr = 0.0001\n",
            "2025-04-17 10:37:55 INFO     Epoch 11 [600/781]: loss = 0.18078309297561646, lr = 0.0001\n",
            "2025-04-17 10:38:29 INFO     Epoch 11 [650/781]: loss = 0.19002699851989746, lr = 0.0001\n",
            "2025-04-17 10:39:03 INFO     Epoch 11 [700/781]: loss = 0.18963387608528137, lr = 0.0001\n",
            "2025-04-17 10:39:37 INFO     Epoch 11 [750/781]: loss = 0.19054758548736572, lr = 0.0001\n",
            "2025-04-17 10:39:59 INFO     Epoch 12 [0/781]: loss = 0.18299934267997742, lr = 0.0001\n",
            "2025-04-17 10:40:34 INFO     Epoch 12 [50/781]: loss = 0.19226083159446716, lr = 0.0001\n",
            "2025-04-17 10:41:08 INFO     Epoch 12 [100/781]: loss = 0.18165633082389832, lr = 0.0001\n",
            "2025-04-17 10:41:42 INFO     Epoch 12 [150/781]: loss = 0.19421568512916565, lr = 0.0001\n",
            "2025-04-17 10:42:16 INFO     Epoch 12 [200/781]: loss = 0.1772063672542572, lr = 0.0001\n",
            "2025-04-17 10:42:51 INFO     Epoch 12 [250/781]: loss = 0.17164520919322968, lr = 0.0001\n",
            "2025-04-17 10:43:25 INFO     Epoch 12 [300/781]: loss = 0.17352989315986633, lr = 0.0001\n",
            "2025-04-17 10:43:59 INFO     Epoch 12 [350/781]: loss = 0.16142290830612183, lr = 0.0001\n",
            "2025-04-17 10:44:33 INFO     Epoch 12 [400/781]: loss = 0.1648297756910324, lr = 0.0001\n",
            "2025-04-17 10:45:07 INFO     Epoch 12 [450/781]: loss = 0.17734408378601074, lr = 0.0001\n",
            "2025-04-17 10:45:41 INFO     Epoch 12 [500/781]: loss = 0.17843878269195557, lr = 0.0001\n",
            "2025-04-17 10:46:16 INFO     Epoch 12 [550/781]: loss = 0.21346363425254822, lr = 0.0001\n",
            "2025-04-17 10:46:50 INFO     Epoch 12 [600/781]: loss = 0.16787652671337128, lr = 0.0001\n",
            "2025-04-17 10:47:24 INFO     Epoch 12 [650/781]: loss = 0.20377986133098602, lr = 0.0001\n",
            "2025-04-17 10:47:58 INFO     Epoch 12 [700/781]: loss = 0.19246743619441986, lr = 0.0001\n",
            "2025-04-17 10:48:33 INFO     Epoch 12 [750/781]: loss = 0.18310964107513428, lr = 0.0001\n",
            "2025-04-17 10:48:55 INFO     Epoch 13 [0/781]: loss = 0.18727481365203857, lr = 0.0001\n",
            "2025-04-17 10:49:29 INFO     Epoch 13 [50/781]: loss = 0.20609116554260254, lr = 0.0001\n",
            "2025-04-17 10:50:03 INFO     Epoch 13 [100/781]: loss = 0.15930838882923126, lr = 0.0001\n",
            "2025-04-17 10:50:38 INFO     Epoch 13 [150/781]: loss = 0.1911160945892334, lr = 0.0001\n",
            "2025-04-17 10:51:12 INFO     Epoch 13 [200/781]: loss = 0.1832084357738495, lr = 0.0001\n",
            "2025-04-17 10:51:46 INFO     Epoch 13 [250/781]: loss = 0.2035561203956604, lr = 0.0001\n",
            "2025-04-17 10:52:20 INFO     Epoch 13 [300/781]: loss = 0.17981939017772675, lr = 0.0001\n",
            "2025-04-17 10:52:54 INFO     Epoch 13 [350/781]: loss = 0.18905887007713318, lr = 0.0001\n",
            "2025-04-17 10:53:29 INFO     Epoch 13 [400/781]: loss = 0.15683454275131226, lr = 0.0001\n",
            "2025-04-17 10:54:03 INFO     Epoch 13 [450/781]: loss = 0.17625534534454346, lr = 0.0001\n",
            "2025-04-17 10:54:37 INFO     Epoch 13 [500/781]: loss = 0.18138353526592255, lr = 0.0001\n",
            "2025-04-17 10:55:11 INFO     Epoch 13 [550/781]: loss = 0.19378070533275604, lr = 0.0001\n",
            "2025-04-17 10:55:45 INFO     Epoch 13 [600/781]: loss = 0.18098410964012146, lr = 0.0001\n",
            "2025-04-17 10:56:20 INFO     Epoch 13 [650/781]: loss = 0.19760063290596008, lr = 0.0001\n",
            "2025-04-17 10:56:54 INFO     Epoch 13 [700/781]: loss = 0.1794654130935669, lr = 0.0001\n",
            "2025-04-17 10:57:28 INFO     Epoch 13 [750/781]: loss = 0.18214258551597595, lr = 0.0001\n",
            "2025-04-17 10:57:50 INFO     Epoch 14 [0/781]: loss = 0.18179833889007568, lr = 0.0001\n",
            "2025-04-17 10:58:24 INFO     Epoch 14 [50/781]: loss = 0.18179862201213837, lr = 0.0001\n",
            "2025-04-17 10:58:59 INFO     Epoch 14 [100/781]: loss = 0.17488645017147064, lr = 0.0001\n",
            "2025-04-17 10:59:33 INFO     Epoch 14 [150/781]: loss = 0.18776550889015198, lr = 0.0001\n",
            "2025-04-17 11:00:07 INFO     Epoch 14 [200/781]: loss = 0.18034110963344574, lr = 0.0001\n",
            "2025-04-17 11:00:41 INFO     Epoch 14 [250/781]: loss = 0.20491795241832733, lr = 0.0001\n",
            "2025-04-17 11:01:15 INFO     Epoch 14 [300/781]: loss = 0.17326991260051727, lr = 0.0001\n",
            "2025-04-17 11:01:49 INFO     Epoch 14 [350/781]: loss = 0.1834104061126709, lr = 0.0001\n",
            "2025-04-17 11:02:24 INFO     Epoch 14 [400/781]: loss = 0.16781489551067352, lr = 0.0001\n",
            "2025-04-17 11:02:58 INFO     Epoch 14 [450/781]: loss = 0.18514135479927063, lr = 0.0001\n",
            "2025-04-17 11:03:32 INFO     Epoch 14 [500/781]: loss = 0.19530169665813446, lr = 0.0001\n",
            "2025-04-17 11:04:06 INFO     Epoch 14 [550/781]: loss = 0.1928226351737976, lr = 0.0001\n",
            "2025-04-17 11:04:40 INFO     Epoch 14 [600/781]: loss = 0.1801549643278122, lr = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KW301QW7RqwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir output_cifar10\n"
      ],
      "metadata": {
        "id": "GGufxAzLRsmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install submitit"
      ],
      "metadata": {
        "id": "EC8oAM6hRv7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa1d10b-0eb4-4095-83a0-d2ae8b9c2d68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import uuid  # Import the uuid module (although it's already in your submitit_train.py)\n",
        "\n",
        "shared_dir = \"/content/shared_experiments\" # Choose a path within /content/\n",
        "\n",
        "if not Path(shared_dir).is_dir():\n",
        "    os.makedirs(shared_dir, exist_ok=True)\n",
        "\n",
        "def get_shared_folder(shared_dir: str) -> Path:\n",
        "    user = os.getenv(\"USER\", \"default_user\") # Colab might not always have USER set\n",
        "    p = Path(shared_dir) / user / \"experiments\"\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def get_init_file(shared_dir: str):\n",
        "    shared_folder = get_shared_folder(shared_dir)\n",
        "    init_file = shared_folder / f\"{uuid.uuid4().hex}_init\"\n",
        "    if init_file.exists():\n",
        "        os.remove(str(init_file))\n",
        "    return init_file\n",
        "\n",
        "# You can optionally run these lines to see the paths that will be used\n",
        "job_dir = get_shared_folder(shared_dir) / \"my_job\" # Example job directory\n",
        "print(f\"Job directory: {job_dir}\")\n",
        "init_file = get_init_file(shared_dir)\n",
        "print(f\"Init file: {init_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opZ2B51vax81",
        "outputId": "80f67486-bdbc-4377-de6f-9adf01ee8dcf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job directory: /content/shared_experiments/default_user/experiments/my_job\n",
            "Init file: /content/shared_experiments/default_user/experiments/91b8b8755bda4b568b191291ed315ac4_init\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python submitit_train.py \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=64 \\\n",
        "    --nodes=1 \\\n",
        "    --accum_iter=1 \\\n",
        "    --eval_frequency=100 \\\n",
        "    --epochs=3000 \\\n",
        "    --class_drop_prob=1.0 \\\n",
        "    --cfg_scale=0.0 \\\n",
        "    --compute_fid \\\n",
        "    --ode_method heun2 \\\n",
        "    --ode_options '{\"nfe\": 50}' \\\n",
        "    --use_ema \\\n",
        "    --edm_schedule \\\n",
        "    --skewed_timesteps \\\n",
        "    --output_dir output_cifar10_submitit \\\n",
        "    --shared_dir \"/content/shared_experiments\""
      ],
      "metadata": {
        "id": "oAubohbgUUl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d23d64-c3e1-4b74-d791-c065b7fa345b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-21 18:00:47 INFO     Submitted job 15124\n"
          ]
        }
      ]
    }
  ]
}